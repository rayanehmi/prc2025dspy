{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff52ef8",
   "metadata": {},
   "source": [
    "## DSPy process\n",
    "\n",
    "Note: I use my own fork of DSPy because I had to implement asynchronous batching: https://github.com/rayanehmi/dspy/tree/feat/async_batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18693820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "import os \n",
    "\n",
    "DATA_PATH = Path.cwd().parent / \"data\"\n",
    "DATA_TYPE : Literal[\"train\", \"rank\", \"final\"] = \"final\"\n",
    "OUTPUT_DIR = os.path.join(DATA_PATH, DATA_TYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5aef113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayte\\Work\\prc2025dspy\\data\\final\\llm_segments.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx</th><th>flight_id</th><th>fuel_kg</th><th>flight_date</th><th>aircraft_type</th><th>origin_name</th><th>destination_name</th><th>track_points_compact</th><th>vertical_rate_balance</th></tr><tr><td>i64</td><td>str</td><td>null</td><td>date</td><td>str</td><td>str</td><td>str</td><td>str</td><td>struct[3]</td></tr></thead><tbody><tr><td>0</td><td>&quot;prc806615763&quot;</td><td>null</td><td>2025-09-01</td><td>&quot;A320&quot;</td><td>&quot;Guadalajara International Airp…</td><td>&quot;Oakland International Airport&quot;</td><td>&quot;time 2025-09-01T03:03:10.92500…</td><td>{0.0,0.0,1.0}</td></tr><tr><td>1</td><td>&quot;prc806615763&quot;</td><td>null</td><td>2025-09-01</td><td>&quot;A320&quot;</td><td>&quot;Guadalajara International Airp…</td><td>&quot;Oakland International Airport&quot;</td><td>&quot;time 2025-09-01T03:07:51.58400…</td><td>{0.0,0.0,1.0}</td></tr><tr><td>2</td><td>&quot;prc806615763&quot;</td><td>null</td><td>2025-09-01</td><td>&quot;A320&quot;</td><td>&quot;Guadalajara International Airp…</td><td>&quot;Oakland International Airport&quot;</td><td>&quot;time 2025-09-01T03:12:50.92100…</td><td>{0.0,0.0,1.0}</td></tr><tr><td>3</td><td>&quot;prc806615763&quot;</td><td>null</td><td>2025-09-01</td><td>&quot;A320&quot;</td><td>&quot;Guadalajara International Airp…</td><td>&quot;Oakland International Airport&quot;</td><td>&quot;time 2025-09-01T03:17:51.40400…</td><td>{0.0,0.0,1.0}</td></tr><tr><td>4</td><td>&quot;prc806615763&quot;</td><td>null</td><td>2025-09-01</td><td>&quot;A320&quot;</td><td>&quot;Guadalajara International Airp…</td><td>&quot;Oakland International Airport&quot;</td><td>&quot;time 2025-09-01T03:22:50.53900…</td><td>{0.0,0.0,1.0}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌─────┬─────────────┬─────────┬────────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ idx ┆ flight_id   ┆ fuel_kg ┆ flight_dat ┆ … ┆ origin_nam ┆ destinatio ┆ track_poin ┆ vertical_r │\n",
       "│ --- ┆ ---         ┆ ---     ┆ e          ┆   ┆ e          ┆ n_name     ┆ ts_compact ┆ ate_balanc │\n",
       "│ i64 ┆ str         ┆ null    ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---        ┆ e          │\n",
       "│     ┆             ┆         ┆ date       ┆   ┆ str        ┆ str        ┆ str        ┆ ---        │\n",
       "│     ┆             ┆         ┆            ┆   ┆            ┆            ┆            ┆ struct[3]  │\n",
       "╞═════╪═════════════╪═════════╪════════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 0   ┆ prc80661576 ┆ null    ┆ 2025-09-01 ┆ … ┆ Guadalajar ┆ Oakland    ┆ time 2025- ┆ {0.0,0.0,1 │\n",
       "│     ┆ 3           ┆         ┆            ┆   ┆ a Internat ┆ Internatio ┆ 09-01T03:0 ┆ .0}        │\n",
       "│     ┆             ┆         ┆            ┆   ┆ ional      ┆ nal        ┆ 3:10.92500 ┆            │\n",
       "│     ┆             ┆         ┆            ┆   ┆ Airp…      ┆ Airport    ┆ …          ┆            │\n",
       "│ 1   ┆ prc80661576 ┆ null    ┆ 2025-09-01 ┆ … ┆ Guadalajar ┆ Oakland    ┆ time 2025- ┆ {0.0,0.0,1 │\n",
       "│     ┆ 3           ┆         ┆            ┆   ┆ a Internat ┆ Internatio ┆ 09-01T03:0 ┆ .0}        │\n",
       "│     ┆             ┆         ┆            ┆   ┆ ional      ┆ nal        ┆ 7:51.58400 ┆            │\n",
       "│     ┆             ┆         ┆            ┆   ┆ Airp…      ┆ Airport    ┆ …          ┆            │\n",
       "│ 2   ┆ prc80661576 ┆ null    ┆ 2025-09-01 ┆ … ┆ Guadalajar ┆ Oakland    ┆ time 2025- ┆ {0.0,0.0,1 │\n",
       "│     ┆ 3           ┆         ┆            ┆   ┆ a Internat ┆ Internatio ┆ 09-01T03:1 ┆ .0}        │\n",
       "│     ┆             ┆         ┆            ┆   ┆ ional      ┆ nal        ┆ 2:50.92100 ┆            │\n",
       "│     ┆             ┆         ┆            ┆   ┆ Airp…      ┆ Airport    ┆ …          ┆            │\n",
       "│ 3   ┆ prc80661576 ┆ null    ┆ 2025-09-01 ┆ … ┆ Guadalajar ┆ Oakland    ┆ time 2025- ┆ {0.0,0.0,1 │\n",
       "│     ┆ 3           ┆         ┆            ┆   ┆ a Internat ┆ Internatio ┆ 09-01T03:1 ┆ .0}        │\n",
       "│     ┆             ┆         ┆            ┆   ┆ ional      ┆ nal        ┆ 7:51.40400 ┆            │\n",
       "│     ┆             ┆         ┆            ┆   ┆ Airp…      ┆ Airport    ┆ …          ┆            │\n",
       "│ 4   ┆ prc80661576 ┆ null    ┆ 2025-09-01 ┆ … ┆ Guadalajar ┆ Oakland    ┆ time 2025- ┆ {0.0,0.0,1 │\n",
       "│     ┆ 3           ┆         ┆            ┆   ┆ a Internat ┆ Internatio ┆ 09-01T03:2 ┆ .0}        │\n",
       "│     ┆             ┆         ┆            ┆   ┆ ional      ┆ nal        ┆ 2:50.53900 ┆            │\n",
       "│     ┆             ┆         ┆            ┆   ┆ Airp…      ┆ Airport    ┆ …          ┆            │\n",
       "└─────┴─────────────┴─────────┴────────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load complete data\n",
    "import polars as pl\n",
    "\n",
    "SEGMENTS_PATH = os.path.join(OUTPUT_DIR, \"llm_segments.parquet\")\n",
    "print(SEGMENTS_PATH)\n",
    "initial_df = pl.read_parquet(SEGMENTS_PATH)\n",
    "initial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae0dcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996abaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "gpt_4_1 = dspy.LM(\"openai/gpt-4.1\", api_key=api_key)\n",
    "gpt_4_1_nano = dspy.LM(\"openai/gpt-4.1-nano\", api_key=api_key)\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "gpt_oss_120b = dspy.LM(\"groq/openai/gpt-oss-120b\", api_key=groq_api_key, cache=False)\n",
    "gpt_5_1_instant = dspy.LM(\"openai/gpt-5.1\", api_key=api_key, temperature=1.0, max_tokens=32000, reasoning_effort=\"none\", cache=False)\n",
    "\n",
    "# json_adapter = dspy.JSONAdapter()  # made the first batch fail?\n",
    "\n",
    "dspy.configure(lm=gpt_oss_120b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99a68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class BurntFuelPrediction(dspy.Signature):\n",
    "    \"\"\"Predict the amount of fuel burnt in kgs by the plane over the given segment of flight.\n",
    "    Segment data is constructed from noisy telemetry: use your common sense if values seem wrong.\n",
    "    hint: vertical_rate_balance contains positive_frac, negative_frac and near_zero_frac, each corresponding \n",
    "    to the share of samples where vertical rate is respectively more than, less than or around 64 ft/min.\n",
    "    hint 2: estimate the fuel weight penalty (heavy in the beginning, lighter in the end).\n",
    "    \"\"\"\n",
    "    features : dict[str, Any] = dspy.InputField()\n",
    "    fuel_kg : float = dspy.OutputField() \n",
    "\n",
    "# Zero-shot chain of thought\n",
    "fuel_cot = dspy.ChainOfThought(BurntFuelPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88c651b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dspy_examples(row, with_fuel: bool = True):\n",
    "    \"\"\"Converts a row to a dspy.Example.\"\"\"\n",
    "    row_data = row.to_dicts()[0] if hasattr(row, \"to_dicts\") else row\n",
    "\n",
    "    def clean(value):\n",
    "        return \"\" if value is None else value\n",
    "\n",
    "    inputs = [\n",
    "        \"idx\",\n",
    "        \"aircraft_type\",\n",
    "        \"origin_name\",\n",
    "        \"origin_destination\",\n",
    "        \"track_points_compact\",\n",
    "        \"track_points_compact\",\n",
    "        \"vertical_rate_balance\"\n",
    "    ]\n",
    "    \n",
    "    features = {key: clean(row_data.get(key)) for key in inputs}\n",
    "    example = dspy.Example(features=features).with_inputs(\"features\")\n",
    "    if with_fuel:\n",
    "        example.fuel_kg = clean(row_data.get(\"fuel_kg\"))\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52f1ad12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'features': {'idx': 0, 'aircraft_type': 'A320', 'origin_name': 'Guadalajara International Airport', 'origin_destination': '', 'track_points_compact': 'time 2025-09-01T03:03:10.925000->2025-09-01T03:07:51.584000 (4.678 min) | sources acars:2, adsb:557 | altitude 3.6e+04 -> 3.598e+04 -> 3.602e+04 -> 3.601e+04 (delta 9, range 50, mean 3.6e+04) | groundspeed 446 -> 448 -> 447 -> 447 (delta 1, range 2, mean 447.3) | vertical_rate 0 -> 0 -> 0 -> -64 (delta -64, range 128, mean 8.989) | mach 0.746 -> 0.749 (delta 0.003, range 0.003, mean 0.7475) | path 31.75/-116.8 -> 31.96/-116.9 -> 32.13/-117 -> 32.29/-117.1 | delta_lat 0.5339 delta_lon -0.3661 | phase cruise | vr balance +0.00 / -0.00 / ~0 1.00', 'vertical_rate_balance': {'positive_frac': 0.0, 'negative_frac': 0.0, 'near_zero_frac': 1.0}}}) (input_keys={'features'})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    df_to_dspy_examples(row, with_fuel=False)\n",
    "    for row in initial_df.iter_rows(named=True)\n",
    "]\n",
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6aaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "randomized_examples = copy.deepcopy(examples)\n",
    "random.Random(42).shuffle(randomized_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e599bc6",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a9fda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10000.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def float_metric(gold: dspy.Example, pred: dspy.Prediction, trace=None):\n",
    "    \"\"\"Return a scalar score (negative squared error) for the evaluator.\"\"\"\n",
    "    true_value = gold.fuel_kg\n",
    "    pred_value = pred.fuel_kg\n",
    "    if true_value is None or pred_value is None:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    squared_error = (true_value - pred_value) ** 2\n",
    "\n",
    "    if trace is None: # if we're doing evaluation or optimization\n",
    "        return -squared_error\n",
    "    else:  # During bootstrapping / trace collection we simply mark good demos.\n",
    "        return squared_error < 40000  # Squared error 200.\n",
    "    \n",
    "fake_example = dspy.Example(features={\"foo\": \"bar\"}, fuel_kg=500.0)\n",
    "fake_prediction = dspy.Prediction(features={\"foo\": \"bar\"}, fuel_kg=600.0)\n",
    "print(float_metric(fake_example, fake_prediction))  # error -100.0\n",
    "print(float_metric(fake_example, fake_prediction, trace='foo'))  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbca704",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0623d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c02c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_50 = Evaluate(\n",
    "    devset=randomized_examples[:50],\n",
    "    num_threads=50, \n",
    "    display_progress=True, \n",
    "    display_table=True\n",
    ")\n",
    "\n",
    "evaluator_500 = Evaluate(\n",
    "    devset=randomized_examples[:400],\n",
    "    num_threads=15, \n",
    "    display_progress=True, \n",
    "    display_table=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dspy.context(lm=gpt_oss_120b):\n",
    "    eval_results = evaluator_500(fuel_cot, metric=float_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786bbf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(eval_results):\n",
    "    rmse = math.sqrt(abs(eval_results.score)/len(eval_results.results))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rmse(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cdb918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump in a csv file\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "results_list = []\n",
    "for result in eval_results.results:\n",
    "    true_value = result[0].fuel_burnt\n",
    "    reasoning = result[1].reasoning\n",
    "    pred_value = result[1].fuel_burnt\n",
    "    metric = result[2]\n",
    "    results_list.append({\n",
    "        \"true_value\": true_value,\n",
    "        \"reasoning\": reasoning,\n",
    "        \"pred_value\": pred_value,\n",
    "        \"metric\": metric\n",
    "    })\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"eval_results.csv\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf789e9",
   "metadata": {},
   "source": [
    "## Batch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7093301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb36661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14926.35it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_minibatch(examples, n_examples_per_batch = 10000):\n",
    "    list_of_batches = []\n",
    "    for i in tqdm(\n",
    "        range(0, len(examples), n_examples_per_batch)\n",
    "    ):\n",
    "        batch_range = examples[i : i + n_examples_per_batch]\n",
    "        list_of_batches.append(batch_range)\n",
    "    return list_of_batches\n",
    "\n",
    "list_of_batches = create_minibatch(examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39b7f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m list_of_artifacts = []\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (i, minibatch) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28menumerate\u001b[39m(list_of_batches), total=\u001b[38;5;28mlen\u001b[39m(list_of_batches)):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# 1. create a jsonl file\u001b[39;00m\n\u001b[32m      6\u001b[39m     artifact = fuel_cot.create_batch_file(\n\u001b[32m      7\u001b[39m         minibatch,\n\u001b[32m      8\u001b[39m         input_file_path=os.path.join(OUTPUT_DIR, \u001b[33m\"\u001b[39m\u001b[33mbatches\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(i)+\u001b[33m\"\u001b[39m\u001b[33m.jsonl\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      9\u001b[39m         \u001b[38;5;66;03m# endpoint=\"/v1/chat/completions\"\u001b[39;00m\n\u001b[32m     10\u001b[39m     )\n\u001b[32m     11\u001b[39m     list_of_artifacts.append(artifact)\n",
      "\u001b[31mNameError\u001b[39m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_batch_files(list_of_batches: list):\n",
    "    \"\"\"Takes a list of minibatches and creates the files\"\"\"\n",
    "    list_of_artifacts = []\n",
    "    for (i, minibatch) in tqdm(enumerate(list_of_batches), total=len(list_of_batches)):\n",
    "        # 1. create a jsonl file\n",
    "        artifact = fuel_cot.create_batch_file(\n",
    "            minibatch,\n",
    "            input_file_path=os.path.join(OUTPUT_DIR, \"batches\", str(i)+\".jsonl\"),\n",
    "            # endpoint=\"/v1/chat/completions\"\n",
    "        )\n",
    "        list_of_artifacts.append(artifact)\n",
    "    return list_of_artifacts\n",
    "\n",
    "list_of_artifacts = create_batch_files(list_of_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3253eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. send it to the endpoint\n",
    "# DANGER :)\n",
    "async def send_batches(list_of_artifacts):\n",
    "    batch_handles = [\n",
    "        await fuel_cot.asubmit_batch_file(\n",
    "            artifact,\n",
    "            completion_window=\"24h\",\n",
    "        ) for artifact in list_of_artifacts\n",
    "    ]\n",
    "    return batch_handles\n",
    "\n",
    "batch_handles = await send_batches(list_of_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8d0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_of_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mcheckpoint_list_of_batches.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:  \u001b[38;5;66;03m# open a text file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     pickle.dump(\u001b[43mlist_of_batches\u001b[49m, f) \u001b[38;5;66;03m# serialize the list\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mcheckpoint_list_of_artifacts.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:  \u001b[38;5;66;03m# open a text file\u001b[39;00m\n\u001b[32m      5\u001b[39m     pickle.dump(list_of_artifacts, f) \u001b[38;5;66;03m# serialize the list\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'list_of_batches' is not defined"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# with open('checkpoint_list_of_batches.pkl', 'wb') as f:  # open a text file\n",
    "#     pickle.dump(list_of_batches, f) # serialize the list\n",
    "# with open('checkpoint_list_of_artifacts.pkl', 'wb') as f:  # open a text file\n",
    "#     pickle.dump(list_of_artifacts, f) # serialize the list\n",
    "# with open('checkpoint_batch_handles.pkl', 'wb') as f:  # open a text file\n",
    "#     pickle.dump(batch_handles, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2384b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('checkpoint_list_of_batches.pkl', 'rb') as f:\n",
    "    list_of_batches = pickle.load(f)\n",
    "with open('checkpoint_list_of_artifacts.pkl', 'rb') as f:\n",
    "    list_of_artifacts = pickle.load(f)\n",
    "with open('checkpoint_batch_handles.pkl', 'rb') as f:\n",
    "    batch_handles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27bb3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. and finally retrieve the predictions\n",
    "responses = [\n",
    "    await fuel_cot.aretrieve_batch_predictions(\n",
    "        batch_handle.batch_id,\n",
    "        artifact,\n",
    "        custom_llm_provider=\"groq\",\n",
    "        download_output_path=os.path.join(OUTPUT_DIR, \"batches_output\", batch_handle.batch_id),  # optional, defaults next to metadata\n",
    "        return_failed_items=True,\n",
    "    ) for batch_handle, artifact in zip(batch_handles, list_of_artifacts)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c82bfb",
   "metadata": {},
   "source": [
    "Create a df with input/preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5066bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "failures_to_retry = []\n",
    "\n",
    "for (preds, failures), artifact in zip(responses, list_of_artifacts):\n",
    "    examples = artifact.metadata[\"examples\"]\n",
    "    for idx, pred in enumerate(preds):\n",
    "        row = {\n",
    "            **examples[idx][\"inputs\"],              # original features\n",
    "            \"custom_id\": examples[idx][\"custom_id\"]\n",
    "        }\n",
    "        if pred is None:\n",
    "            row[\"fuel_kg\"] = None\n",
    "            row[\"reasoning\"] = None\n",
    "        else:\n",
    "            outputs = pred.toDict()\n",
    "            row[\"fuel_kg\"] = outputs[\"fuel_kg\"]\n",
    "            row[\"reasoning\"] = outputs[\"reasoning\"]\n",
    "        rows.append(row)\n",
    "\n",
    "    for failure in failures:\n",
    "        failures_to_retry.append(\n",
    "            examples[failure.index][\"inputs\"]\n",
    "        )\n",
    "\n",
    "final_df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fcf5ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def responses_to_dataframe(\n",
    "    responses,\n",
    "    artifacts,\n",
    "    *,\n",
    "    feature_col: str = \"features\",\n",
    "    prediction_cols: tuple[str, str] = (\"reasoning\", \"fuel_kg\"),\n",
    "    nested_feature_key: str = \"features\",  # the key inside artifact metadata\n",
    "    index_field: str = \"idx\",\n",
    "):\n",
    "    rows: list[dict] = []\n",
    "    failures_to_retry: list[dict] = []\n",
    "\n",
    "    for (preds, failures), artifact in zip(responses, artifacts):\n",
    "        examples = artifact.metadata[\"examples\"]\n",
    "        for idx, pred in enumerate(preds):\n",
    "            inputs = examples[idx][\"inputs\"]\n",
    "            nested_features = inputs.get(nested_feature_key, inputs)\n",
    "\n",
    "            row = {\n",
    "                feature_col: nested_features,                # keep the full feature dict\n",
    "                \"custom_id\": examples[idx][\"custom_id\"],\n",
    "                index_field: nested_features.get(index_field),\n",
    "            }\n",
    "\n",
    "            if pred is None:\n",
    "                for col in prediction_cols:\n",
    "                    row[col] = None\n",
    "            else:\n",
    "                outputs = pred.toDict()\n",
    "                for col in prediction_cols:\n",
    "                    row[col] = outputs.get(col)\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "        for failure in failures:\n",
    "            failures_to_retry.append(examples[failure.index][\"inputs\"])\n",
    "\n",
    "    final_df = pd.DataFrame(rows)\n",
    "    return final_df, failures_to_retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d62771d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, retry_payloads = responses_to_dataframe(\n",
    "    responses,\n",
    "    list_of_artifacts,\n",
    "    feature_col=\"features\",\n",
    "    prediction_cols=(\"reasoning\", \"fuel_kg\"),\n",
    "    nested_feature_key=\"features\",\n",
    "    index_field=\"idx\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1848a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>idx</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>fuel_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'idx': 0, 'aircraft_type': 'A320', 'origin_na...</td>\n",
       "      <td>chainofthought-0-e95bae8c</td>\n",
       "      <td>0</td>\n",
       "      <td>The segment lasts 4.678 minutes (≈0.078 hours)...</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'idx': 1, 'aircraft_type': 'A320', 'origin_na...</td>\n",
       "      <td>chainofthought-1-2cca347b</td>\n",
       "      <td>1</td>\n",
       "      <td>The segment lasts about 5 minutes (4.989 min ≈...</td>\n",
       "      <td>208.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'idx': 2, 'aircraft_type': 'A320', 'origin_na...</td>\n",
       "      <td>chainofthought-2-c0dfb547</td>\n",
       "      <td>2</td>\n",
       "      <td>The segment lasts about 5 minutes (0.0835 h) a...</td>\n",
       "      <td>200.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'idx': 3, 'aircraft_type': 'A320', 'origin_na...</td>\n",
       "      <td>chainofthought-3-0a205acf</td>\n",
       "      <td>3</td>\n",
       "      <td>The segment lasts just under 5 minutes (4.986 ...</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'idx': 4, 'aircraft_type': 'A320', 'origin_na...</td>\n",
       "      <td>chainofthought-4-f785a9d4</td>\n",
       "      <td>4</td>\n",
       "      <td>The segment lasts about 5.0 minutes (0.0833 ho...</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  \\\n",
       "0  {'idx': 0, 'aircraft_type': 'A320', 'origin_na...   \n",
       "1  {'idx': 1, 'aircraft_type': 'A320', 'origin_na...   \n",
       "2  {'idx': 2, 'aircraft_type': 'A320', 'origin_na...   \n",
       "3  {'idx': 3, 'aircraft_type': 'A320', 'origin_na...   \n",
       "4  {'idx': 4, 'aircraft_type': 'A320', 'origin_na...   \n",
       "\n",
       "                   custom_id  idx  \\\n",
       "0  chainofthought-0-e95bae8c    0   \n",
       "1  chainofthought-1-2cca347b    1   \n",
       "2  chainofthought-2-c0dfb547    2   \n",
       "3  chainofthought-3-0a205acf    3   \n",
       "4  chainofthought-4-f785a9d4    4   \n",
       "\n",
       "                                           reasoning  fuel_kg  \n",
       "0  The segment lasts 4.678 minutes (≈0.078 hours)...    190.0  \n",
       "1  The segment lasts about 5 minutes (4.989 min ≈...    208.3  \n",
       "2  The segment lasts about 5 minutes (0.0835 h) a...    200.3  \n",
       "3  The segment lasts just under 5 minutes (4.986 ...    210.0  \n",
       "4  The segment lasts about 5.0 minutes (0.0833 ho...    219.0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c38d25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61745"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03bc4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "810b34c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3989"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df[final_df[\"fuel_kg\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5502624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dspy\n",
    "\n",
    "async def round_v2(\n",
    "    module: dspy.Module,\n",
    "    final_df: pd.DataFrame,\n",
    "    *,\n",
    "    feature_column: str = \"features\",\n",
    "    prediction_columns: tuple[str, str] = (\"reasoning\", \"fuel_kg\"),\n",
    "    index_column: str = \"idx\",\n",
    "    n_pred_per_batch: int = 10_000,\n",
    "    minimal_batch_threshold: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fill missing predictions in `final_df` by calling `module`.\n",
    "    Adds/updates `index_column` so you can join back to the original dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def to_example(payload):\n",
    "        if isinstance(payload, dspy.Example):\n",
    "            return payload\n",
    "        if isinstance(payload, dict):\n",
    "            nested = payload.get(\"features\", payload)\n",
    "            return dspy.Example(features=nested).with_inputs(\"features\")\n",
    "        raise TypeError(...)\n",
    "\n",
    "\n",
    "    def get_idx(payload):\n",
    "        if isinstance(payload, dspy.Example):\n",
    "            data = payload.inputs().toDict().get(\"features\", payload.inputs().toDict())\n",
    "        elif isinstance(payload, dict):\n",
    "            data = payload.get(\"features\", payload)\n",
    "        else:\n",
    "            return None\n",
    "        return data.get(\"idx\")\n",
    "\n",
    "\n",
    "    if index_column not in final_df.columns:\n",
    "        final_df[index_column] = pd.NA\n",
    "\n",
    "    missing_mask = final_df[prediction_columns[-1]].isna()\n",
    "    pending_idx = final_df.index[missing_mask].tolist()\n",
    "    if not pending_idx:\n",
    "        return final_df, 0, 0\n",
    "\n",
    "    pending_idx = pending_idx[:n_pred_per_batch]\n",
    "    indexed_examples = []\n",
    "    for row_idx in pending_idx:\n",
    "        payload = final_df.at[row_idx, feature_column]\n",
    "        example = to_example(payload)\n",
    "        # make sure we keep the original idx visible on the dataframe\n",
    "        idx_value = get_idx(payload)\n",
    "        if idx_value is not None:\n",
    "            final_df.at[row_idx, index_column] = idx_value\n",
    "        indexed_examples.append((row_idx, example))\n",
    "\n",
    "    examples = [ex for _, ex in indexed_examples]\n",
    "    newly_filled = 0\n",
    "\n",
    "    if len(examples) < minimal_batch_threshold:\n",
    "        predictions, failed_examples, _ = module.batch(\n",
    "            examples,\n",
    "            return_failed_examples=True,\n",
    "        )\n",
    "        for (row_idx, _), pred in zip(indexed_examples, predictions):\n",
    "            if pred is None:\n",
    "                continue\n",
    "            values = pred.toDict()\n",
    "            for col in prediction_columns:\n",
    "                final_df.at[row_idx, col] = values.get(col)\n",
    "            newly_filled += 1\n",
    "        remaining = len(pending_idx) - newly_filled\n",
    "        return final_df, newly_filled, remaining\n",
    "\n",
    "    preds, failures = await module.abatch(\n",
    "        examples,\n",
    "        return_failed_items=True,\n",
    "    )\n",
    "    for position, pred in enumerate(preds):\n",
    "        if pred is None:\n",
    "            continue\n",
    "        row_idx = indexed_examples[position][0]\n",
    "        values = pred.toDict()\n",
    "        for col in prediction_columns:\n",
    "            final_df.at[row_idx, col] = values.get(col)\n",
    "        newly_filled += 1\n",
    "\n",
    "    remaining = len(pending_idx) - newly_filled\n",
    "    return final_df, newly_filled, remaining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a24b67d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2 / 2 examples: 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "Filled 2 rows; 0 still NaN.\n"
     ]
    }
   ],
   "source": [
    "final_df, filled, remaining = await round_v2(\n",
    "    fuel_cot,\n",
    "    final_df,\n",
    "    n_pred_per_batch=10_000,\n",
    "    minimal_batch_threshold=200,\n",
    ")\n",
    "\n",
    "print(f\"Filled {filled} rows; {remaining} still NaN.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "103f3a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df[final_df[\"fuel_kg\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "212bd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('final_df.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(final_df, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f34ac49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['features', 'custom_id', 'idx', 'reasoning', 'fuel_kg'], dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d89cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'flight_id', 'start', 'end', 'fuel_kg'], dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file = pd.read_parquet(os.path.join(DATA_PATH, \"fuel_final_submission.parquet\"))\n",
    "submission_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec0da773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>flight_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>fuel_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:03:10.925</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>2025-09-01 03:27:50.727</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     flight_id                   start                     end fuel_kg\n",
       "0    0  prc806615763 2025-09-01 03:03:10.925 2025-09-01 03:07:51.584    None\n",
       "1    1  prc806615763 2025-09-01 03:07:51.584 2025-09-01 03:12:50.921    None\n",
       "2    2  prc806615763 2025-09-01 03:12:50.921 2025-09-01 03:17:51.404    None\n",
       "3    3  prc806615763 2025-09-01 03:17:51.404 2025-09-01 03:22:50.539    None\n",
       "4    4  prc806615763 2025-09-01 03:22:50.539 2025-09-01 03:27:50.727    None"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f00f02a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the idx column is unique in final_df (drop duplicates if you retried rows)\n",
    "pred_lookup = (\n",
    "    final_df\n",
    "    .dropna(subset=[\"fuel_kg\"])\n",
    "    .drop_duplicates(subset=[\"idx\"], keep=\"last\")\n",
    "    .set_index(\"idx\")[\"fuel_kg\"]\n",
    ")\n",
    "\n",
    "submission_file[\"fuel_kg\"] = submission_file[\"idx\"].map(pred_lookup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239dc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>flight_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>fuel_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:03:10.925</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>2025-09-01 03:27:50.727</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     flight_id                   start                     end  fuel_kg\n",
       "0    0  prc806615763 2025-09-01 03:03:10.925 2025-09-01 03:07:51.584    163.0\n",
       "1    1  prc806615763 2025-09-01 03:07:51.584 2025-09-01 03:12:50.921    165.0\n",
       "2    2  prc806615763 2025-09-01 03:12:50.921 2025-09-01 03:17:51.404    120.0\n",
       "3    3  prc806615763 2025-09-01 03:17:51.404 2025-09-01 03:22:50.539     30.0\n",
       "4    4  prc806615763 2025-09-01 03:22:50.539 2025-09-01 03:27:50.727     38.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7fa174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_parquet(\"llm_submission.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1199e",
   "metadata": {},
   "source": [
    "## Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f61c5be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>flight_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>fuel_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:03:10.925</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>2025-09-01 03:27:50.727</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     flight_id                   start                     end fuel_kg\n",
       "0    0  prc806615763 2025-09-01 03:03:10.925 2025-09-01 03:07:51.584    None\n",
       "1    1  prc806615763 2025-09-01 03:07:51.584 2025-09-01 03:12:50.921    None\n",
       "2    2  prc806615763 2025-09-01 03:12:50.921 2025-09-01 03:17:51.404    None\n",
       "3    3  prc806615763 2025-09-01 03:17:51.404 2025-09-01 03:22:50.539    None\n",
       "4    4  prc806615763 2025-09-01 03:22:50.539 2025-09-01 03:27:50.727    None"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_submission_file = pd.read_parquet(os.path.join(DATA_PATH, \"fuel_rank_submission.parquet\"))\n",
    "rank_submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "50c72331",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lookup = (\n",
    "    final_df\n",
    "    .dropna(subset=[\"fuel_kg\"])\n",
    "    .drop_duplicates(subset=[\"idx\"], keep=\"last\")\n",
    "    .set_index(\"idx\")[\"fuel_kg\"]\n",
    ")\n",
    "\n",
    "rank_submission_file[\"fuel_kg\"] = rank_submission_file[\"idx\"].map(pred_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ea504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>flight_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>fuel_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:03:10.925</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:07:51.584</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:12:50.921</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:17:51.404</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>prc806615763</td>\n",
       "      <td>2025-09-01 03:22:50.539</td>\n",
       "      <td>2025-09-01 03:27:50.727</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     flight_id                   start                     end  fuel_kg\n",
       "0    0  prc806615763 2025-09-01 03:03:10.925 2025-09-01 03:07:51.584    163.0\n",
       "1    1  prc806615763 2025-09-01 03:07:51.584 2025-09-01 03:12:50.921    165.0\n",
       "2    2  prc806615763 2025-09-01 03:12:50.921 2025-09-01 03:17:51.404    120.0\n",
       "3    3  prc806615763 2025-09-01 03:17:51.404 2025-09-01 03:22:50.539     30.0\n",
       "4    4  prc806615763 2025-09-01 03:22:50.539 2025-09-01 03:27:50.727     38.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2f5eace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_submission_file.to_parquet(\"polite-emu_v0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d59d7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_df = final_df.drop(columns=\"features\")\n",
    "shorter_df.to_parquet(\"final_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855fd53f",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5916f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lm in [gpt_oss_120b]:\n",
    "  cost = sum([x['cost'] for x in lm.history if x['cost'] is not None])\n",
    "  print(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prc2025dspy (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
